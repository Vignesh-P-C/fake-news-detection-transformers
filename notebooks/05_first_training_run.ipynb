{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOW1gnCzsnR7OZyRtEB2sMV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vignesh-P-C/fake-news-detection-transformers/blob/main/notebooks_05_first_training_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Training Run (Sanity Check)\n",
        "\n",
        "**Project:** Fake News Detection using Transformers  \n",
        "**Goal:** Verify end-to-end training works and loss decreases\n"
      ],
      "metadata": {
        "id": "-7pAKIuHx1R5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LSnsKNt44ELe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    DistilBertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "MAX_LENGTH = 256"
      ],
      "metadata": {
        "id": "OszkNKLS4EoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "LNkTRTCe4Klz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df = pd.read_csv(\n",
        "    \"Fake.csv\",\n",
        "    engine=\"python\",\n",
        "    sep=\",\",\n",
        "    quotechar='\"',\n",
        "    escapechar=\"\\\\\",\n",
        "    on_bad_lines=\"skip\"\n",
        ")\n",
        "\n",
        "true_df = pd.read_csv(\n",
        "    \"True.csv\",\n",
        "    engine=\"python\",\n",
        "    sep=\",\",\n",
        "    quotechar='\"',\n",
        "    escapechar=\"\\\\\",\n",
        "    on_bad_lines=\"skip\"\n",
        ")\n",
        "\n",
        "fake_df[\"label\"] = 0\n",
        "true_df[\"label\"] = 1\n",
        "\n",
        "df = pd.concat([fake_df, true_df], ignore_index=True)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# FORCE correct types\n",
        "texts = df[\"text\"].astype(str).tolist()\n",
        "labels = df[\"label\"].tolist()"
      ],
      "metadata": {
        "id": "aVz3ee4i4NQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(texts), type(texts[0])"
      ],
      "metadata": {
        "id": "2GiWgm9C4Qi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")"
      ],
      "metadata": {
        "id": "iq1P0qFH4UkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert isinstance(train_texts, list)\n",
        "assert isinstance(train_texts[0], str)"
      ],
      "metadata": {
        "id": "KpK2pplZ4Wbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_texts(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_LENGTH\n",
        "    )\n",
        "\n",
        "train_encodings = tokenize_texts(train_texts)\n",
        "val_encodings = tokenize_texts(val_texts)\n"
      ],
      "metadata": {
        "id": "U1sVx45_4Y24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "WjZx1YI54ouo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NewsDataset(train_encodings, train_labels)\n",
        "val_dataset = NewsDataset(val_encodings, val_labels)"
      ],
      "metadata": {
        "id": "CVh31vNS49AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=2\n",
        ")"
      ],
      "metadata": {
        "id": "xOT5IE3I4_IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "5XffEYtz5Akh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "r7dxUUj55EEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QD6_9kYD5GZZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
