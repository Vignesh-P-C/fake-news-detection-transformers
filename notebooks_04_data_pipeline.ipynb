{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrRcMuTmLz+S1p5pQDpnYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vignesh-P-C/fake-news-detection-transformers/blob/main/notebooks_04_data_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pipeline Preparation\n",
        "\n",
        "**Project:** Fake News Detection using Transformers  \n",
        "**Goal:** Convert raw news text into model-ready tokenized inputs  \n",
        "**Note:** Includes truncation, padding, and dataset preparation\n"
      ],
      "metadata": {
        "id": "cUFplcp6DH29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "qRkIxjj5DJ1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "ph4E99Q-DP35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 256\n"
      ],
      "metadata": {
        "id": "WUwp_s6zDWx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df = pd.read_csv(\n",
        "    \"Fake.csv\",\n",
        "    engine=\"python\",\n",
        "    sep=\",\",\n",
        "    quotechar='\"',\n",
        "    escapechar=\"\\\\\",\n",
        "    on_bad_lines=\"skip\"\n",
        ")\n",
        "\n",
        "true_df = pd.read_csv(\n",
        "    \"True.csv\",\n",
        "    engine=\"python\",\n",
        "    sep=\",\",\n",
        "    quotechar='\"',\n",
        "    escapechar=\"\\\\\",\n",
        "    on_bad_lines=\"skip\"\n",
        ")\n",
        "\n",
        "fake_df[\"label\"] = 0\n",
        "true_df[\"label\"] = 1\n",
        "\n",
        "df = pd.concat([fake_df, true_df], ignore_index=True)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "DHXytKKbDYzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[\"text\"].tolist(),\n",
        "    df[\"label\"].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"label\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "V7PKZXf7DcnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_texts(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_LENGTH\n",
        "    )"
      ],
      "metadata": {
        "id": "0KOtJjmYDoIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenize_texts(train_texts)\n",
        "val_encodings = tokenize_texts(val_texts)\n"
      ],
      "metadata": {
        "id": "nQsTVzmeDqQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_encodings[\"input_ids\"][0])"
      ],
      "metadata": {
        "id": "Q-Bv8bXYDtYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_encodings[\"input_ids\"])\n",
        "len(train_encodings[\"input_ids\"])"
      ],
      "metadata": {
        "id": "oZIcZ-hCDx-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class NewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "tYMNJEC2Dzru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NewsDataset(train_encodings, train_labels)\n",
        "val_dataset = NewsDataset(val_encodings, val_labels)"
      ],
      "metadata": {
        "id": "8_xnKfF6EEqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(val_dataset)\n"
      ],
      "metadata": {
        "id": "VXh8ybwsEG_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "id": "_Plhd4Y2EJ_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8FSrVZ17ENKQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}